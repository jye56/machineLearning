---
title: "Machine Learning Project"
output: html_document
---

# 1. SYNOPSIS

Exercise data were obtained from Groupware Technologies (http://groupware.les.inf.puc-rio.br/har). The dataset has 5 classes  of activity: sitting-down, standing-up, standing, walking, and sitting, desginated as A,B,C,D, and E, collected on 8 hours of activities of 4 healthy subjects, with 159 attributes. After tidying up the data, the data were partitioned into training set and testing set for the purpose of cross validation. Three different models, classification trees model, boosting (gbm) model, and random forest model, were fit. While the classification trees model has the lowest accuracy, only 49.26%, boosting model and random forest model have the accuracy of 98.69% and 99.78%, respectively.

Accuracies calculated using testing data subsets are slightly lower than those calculated using the training data subset (0.4926 vs 0.4965 for classification trees, 0.9869 vs 0.9939 for gbm model, and 0.9978 vs 1.000 for rf model). These numbers are consistent with the expectation that the out of sample error should be higher, i.e, the testing  sample accuracy should be lower. The testing sample error (1-accurary), not the training sample error, is the appropriate estimate for the out-of-sample error.

The above three models predicted 8, 20 and 20 correctly out of 20 test cases in the submission portion of the project.

# 2. Modeling considerations

Classification trees model, boosting model and random forest models were tested because these classification models do not require many assumptions on the underlying data. Aslo, no preprocessing is needed. Model based prediction such as linear discriminaant analysis was not tested. 

Time required for fitting classification trees, gbm model and rf model are approximately 2 minutes, 30 miniutes and 70 minutes, respectively, on my laptop (Intel cpu 2.6GH, Ram 4GB, 64-bit Windows 7).


# 3. Supplemental material/modeling details

The following codes and output are related to data loading, tidying, modeling and accuracy calculations. Exploratory data analysis is not included.

```{r}
# Here are codes that were used to load the data, but commented out for not re-runining it each time
#url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
#download.file(url, destfile="mlTrain.csv")

#url2<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#download.file(url2, destfile="mlTest.csv")
```


### Load libraries

```{r}
suppressMessages(library(dplyr))
suppressMessages(library(caret))
library(ggplot2)
```
### Load data and tidy up data:

For tidying up the data, columns that are secondary (calculated) in nature and are mostly NA are removed. Also, time stamps and index are not expected to contribute to the final model and are therefore removed. The data frame is reduced from 160 columns to 56 columns.

```{r}
mytrain<-read.csv("mlTrain.csv")

mytrain<-select(mytrain, -starts_with("max_"),-starts_with("min_"),-starts_with("amplitude"),-starts_with("kurtosis_"),-starts_with("skewness"),-starts_with("var_"),-starts_with("avg_"),-starts_with("stddev"),-X,-c(raw_timestamp_part_1:cvtd_timestamp))

mytest<-read.csv("mlTest.csv")

mytest<-select(mytest, -starts_with("max_"),-starts_with("min_"),-starts_with("amplitude"),-starts_with("kurtosis_"),-starts_with("skewness"),-starts_with("var_"),-starts_with("avg_"),-starts_with("stddev"),-X,-c(raw_timestamp_part_1:cvtd_timestamp))

```

### Partition the data set for cross validation
```{r,cache=TRUE}
set.seed(1028)
inTrain<-createDataPartition(y=mytrain$classe,p=0.7, list=F)
training<-mytrain[inTrain,]
testing<-mytrain[-inTrain,]

```
### Fit different models

Using tree model to fit the data
```{r,cache=TRUE}

modfittree<-train(classe~.,data=training, method='rpart')

```

Using boosting (gbm) to fit the data
```{r,cache=TRUE}

modfitgbm <- train(classe ~ ., method="gbm", data=training,verbose=FALSE)

```
gbm took 30 min to run on my laptop.

Using random forests to fit the data
```{r,cache=TRUE}

set.seed(1028)
modfitrf<-train(classe~.,data=training,method='rf')

```


### Accuracies of the prediction models

```{r}
length(training[,1]);length(testing[,1])

#predicting on the training data used for model building
predtrain1<-predict(modfittree,newdata=training)
table(predtrain1,training$classe)

#predicting on the test data selected from the train
pred1<-predict(modfittree,newdata=testing)
table(pred1,testing$classe)


#predicting on the training data used for model building
predtrain2<-predict(modfitgbm,newdata=training)
table(predtrain2,training$classe)

#predicting on the test data selected from the train
pred2<-predict(modfitgbm,newdata=testing)
table(pred2,testing$classe)

#predicting on the training data used for model building
predtrain3<-predict(modfitrf,newdata=training)
table(predtrain3,training$classe)

#predicting on the test data selected from the train
pred3<-predict(modfitrf,newdata=testing)
table(pred3,testing$classe)


```
Accuracy can also be more conveniently obtained by using the function confusionMatrix (see below), but nost of the outputs are not shown so that the writeup will not be too lengthy.

```{r}
confusionMatrix(pred3,testing$classe)

```



### Accuracies:

The above data are used to calculate the prediction accuracy for all three models

Accuracy for classification trees:
training data: 6821/13737=0.4965 testing data: 2899/5885=0.4926

Accuracy for gbm model:
training data: 13653/13737=0.9939 testing data: 5808/5885=0.9869

Accuracy for rf model:
training data: 13737/13737=1.000 testing data: 5872/5885=0.9978


